{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement:\n",
        "We have customers data\n",
        "We are trying to predict or not to give a loan"
      ],
      "metadata": {
        "id": "2cnBxoJYidS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary libraries\n",
        "import warnings\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import chi2_contingency\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support"
      ],
      "metadata": {
        "id": "b56hD5z8irUy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset\n",
        "\n",
        "a1 = pd.read_excel(\"case_study1.xlsx\")\n",
        "a2 = pd.read_excel(\"case_study2.xlsx\")\n",
        "\n",
        "# Making copies of the dataset\n",
        "\n",
        "df1 = a1.copy()\n",
        "df2 = a2.copy()"
      ],
      "metadata": {
        "id": "3s0wSAmwuqUt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing the null values in df1\n",
        "\n",
        "df1 = df1.loc[df1['Age_Oldest_TL'] != -99999]"
      ],
      "metadata": {
        "id": "3lkEU3HUypqE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Null values in df2: Removing the column if null values > 10000 ; else removing the rows\n",
        "\n",
        "columns_to_be_removed = []\n",
        "\n",
        "for column in df2.columns:\n",
        "  if df2.loc[df2[column] == -99999].shape[0] > 10000:\n",
        "    columns_to_be_removed.append(column)\n",
        "print(columns_to_be_removed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s970Moot0rd8",
        "outputId": "869dbb30-7f6d-4f29-947a-c3347c332fc8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['time_since_first_deliquency', 'time_since_recent_deliquency', 'max_delinquency_level', 'max_deliq_6mts', 'max_deliq_12mts', 'CC_utilization', 'PL_utilization', 'max_unsec_exposure_inPct']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping the columns with more than 10000 missing values\n",
        "\n",
        "df2 = df2.drop(columns_to_be_removed, axis = 1)"
      ],
      "metadata": {
        "id": "UCZgOlaw2d9u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping the rows with null values (indicated by -99999)\n",
        "\n",
        "for i in df2.columns:\n",
        "  df2 = df2.loc[df2[i] != -99999]"
      ],
      "metadata": {
        "id": "z18ZRF7n3KdX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging the two dataframes using an INNER JOIN, so that no null values are present.\n",
        "\n",
        "df = pd.merge(df1, df2, how = 'inner', left_on = ['PROSPECTID'], right_on = ['PROSPECTID'])"
      ],
      "metadata": {
        "id": "ctQY8eSL3jcI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the categorical columns\n",
        "\n",
        "for column in df.columns:\n",
        "  if df[column].dtype == 'object':\n",
        "    print (column)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6swnW7eq4iaH",
        "outputId": "6278d327-9820-443d-ac44-37a8f1c5a55f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MARITALSTATUS\n",
            "EDUCATION\n",
            "GENDER\n",
            "last_prod_enq2\n",
            "first_prod_enq2\n",
            "Approved_Flag\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We have 5 Categorical Columns: MARITALSTATUS, EDUCATION, GENDER,last_prod_enq2 and first_prod_enq2\n",
        "\n",
        "Now our main task is to figure out how these columns affect the target variable and to find our their statistical significance.\n",
        "\n",
        "To find the statistical significance between two categorical varibles, I will use Chisquare Test with alpha level of 0.05 and Confidence interval of 0.95."
      ],
      "metadata": {
        "id": "g8ovLo8F7jCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing a Chi-square test\n",
        "\n",
        "for i in ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']:\n",
        "    chi2, pval, _, _ = chi2_contingency(pd.crosstab(df[i], df['Approved_Flag']))\n",
        "    print(i, '---', pval)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z4s3iWVByFJ",
        "outputId": "817750dc-c807-4e69-a57c-c5206e6139d6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MARITALSTATUS --- 3.578180861038862e-233\n",
            "EDUCATION --- 2.6942265249737532e-30\n",
            "GENDER --- 1.907936100186563e-05\n",
            "last_prod_enq2 --- 0.0\n",
            "first_prod_enq2 --- 7.84997610555419e-287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Since all the categorical features have a p-value <= 0.05, we will accept all of them."
      ],
      "metadata": {
        "id": "ooWBBZ_zFCtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the numerical variables\n",
        "\n",
        "numeric_columns = []\n",
        "for i in df.columns:\n",
        "    if df[i].dtype != 'object' and i not in ['PROSPECTID','Approved_Flag']:\n",
        "        numeric_columns.append(i)"
      ],
      "metadata": {
        "id": "kkhxPG3DFSYa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Multicolinearity Check using Sequential VIF (=6)**"
      ],
      "metadata": {
        "id": "DlOsYaMuIjDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VIF sequentially check on all columns\n",
        "\n",
        "vif_data = df[numeric_columns]\n",
        "total_columns = vif_data.shape[1]\n",
        "columns_to_be_kept = []\n",
        "column_index = 0\n",
        "\n",
        "\n",
        "\n",
        "for i in range (0,total_columns):\n",
        "\n",
        "    vif_value = variance_inflation_factor(vif_data, column_index)\n",
        "    print (column_index,'---',vif_value)\n",
        "\n",
        "\n",
        "    if vif_value <= 6:\n",
        "        columns_to_be_kept.append( numeric_columns[i] )\n",
        "        column_index = column_index+1\n",
        "\n",
        "    else:\n",
        "        vif_data = vif_data.drop([ numeric_columns[i] ] , axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1kvLItGFu6d",
        "outputId": "1f87e549-bf56-437d-87d4-a8f501227f94"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 --- inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 --- inf\n",
            "0 --- 11.320180023967996\n",
            "0 --- 8.363698035000336\n",
            "0 --- 6.520647877790928\n",
            "0 --- 5.149501618212625\n",
            "1 --- 2.611111040579735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 --- inf\n",
            "2 --- 1788.7926256209232\n",
            "2 --- 8.601028256477228\n",
            "2 --- 3.832800792153077\n",
            "3 --- 6.099653381646723\n",
            "3 --- 5.581352009642766\n",
            "4 --- 1.985584353098778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 --- inf\n",
            "5 --- 4.80953830281934\n",
            "6 --- 23.270628983464636\n",
            "6 --- 30.595522588100053\n",
            "6 --- 4.384346405965583\n",
            "7 --- 3.0646584155234238\n",
            "8 --- 2.898639771299251\n",
            "9 --- 4.377876915347324\n",
            "10 --- 2.207853583695844\n",
            "11 --- 4.916914200506864\n",
            "12 --- 5.214702030064725\n",
            "13 --- 3.3861625024231476\n",
            "14 --- 7.840583309478997\n",
            "14 --- 5.255034641721434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15 --- inf\n",
            "15 --- 7.380634506427238\n",
            "15 --- 1.4210050015175733\n",
            "16 --- 8.083255010190316\n",
            "16 --- 1.6241227524040114\n",
            "17 --- 7.257811920140003\n",
            "17 --- 15.59624383268298\n",
            "17 --- 1.825857047132431\n",
            "18 --- 1.5080839450032664\n",
            "19 --- 2.172088834824578\n",
            "20 --- 2.6233975535272274\n",
            "21 --- 2.2959970812106176\n",
            "22 --- 7.360578319196446\n",
            "22 --- 2.1602387773102567\n",
            "23 --- 2.8686288267891467\n",
            "24 --- 6.458218003637272\n",
            "24 --- 2.8474118865638247\n",
            "25 --- 4.753198156284083\n",
            "26 --- 16.22735475594825\n",
            "26 --- 6.424377256363877\n",
            "26 --- 8.887080381808678\n",
            "26 --- 2.3804746142952653\n",
            "27 --- 8.60951347651454\n",
            "27 --- 13.06755093547673\n",
            "27 --- 3.500040056654653\n",
            "28 --- 1.9087955874813773\n",
            "29 --- 17.006562234161628\n",
            "29 --- 10.730485153719197\n",
            "29 --- 2.3538497522950275\n",
            "30 --- 22.10485591513649\n",
            "30 --- 2.7971639638512924\n",
            "31 --- 3.424171203217696\n",
            "32 --- 10.175021454450922\n",
            "32 --- 6.408710354561292\n",
            "32 --- 1.001151196262563\n",
            "33 --- 3.069197305397273\n",
            "34 --- 2.8091261600643724\n",
            "35 --- 20.249538381980678\n",
            "35 --- 15.864576541593774\n",
            "35 --- 1.833164974053215\n",
            "36 --- 1.5680839909542046\n",
            "37 --- 1.9307572353811682\n",
            "38 --- 4.331265056645244\n",
            "39 --- 9.390334396150173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## After performing Sequential VIF, 33 features were dropped. Now we have 39 features and there is close to no multicolinearity between these features. (<6 threshold)"
      ],
      "metadata": {
        "id": "PrY0-ebBKZRB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ANOVA Test**\n",
        "\n",
        "## Now that we have only 39 features left, we will perform an ANOVA test of each variable to the target variable and check for its statistical significance at a p-value of 0.05."
      ],
      "metadata": {
        "id": "ZAYdGP_cK3ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import f_oneway\n",
        "\n",
        "columns_to_be_kept_numerical = []\n",
        "\n",
        "for i in columns_to_be_kept:\n",
        "    a = list(df[i])\n",
        "    b = list(df['Approved_Flag'])\n",
        "\n",
        "    group_P1 = [value for value, group in zip(a, b) if group == 'P1']\n",
        "    group_P2 = [value for value, group in zip(a, b) if group == 'P2']\n",
        "    group_P3 = [value for value, group in zip(a, b) if group == 'P3']\n",
        "    group_P4 = [value for value, group in zip(a, b) if group == 'P4']\n",
        "\n",
        "\n",
        "    f_statistic, p_value = f_oneway(group_P1, group_P2, group_P3, group_P4)\n",
        "\n",
        "    if p_value <= 0.05:\n",
        "        columns_to_be_kept_numerical.append(i)"
      ],
      "metadata": {
        "id": "vddyf2ReLKAC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## After applying ANOVA on 39 features, we now have 37 columns with no multicolinearity and no correlation with the prediction variable."
      ],
      "metadata": {
        "id": "xEXIprQqMHMf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Selection is done for the Categorical and Numerical Variables."
      ],
      "metadata": {
        "id": "JovGKT3BVM-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Listing all the final features\n",
        "features = columns_to_be_kept_numerical + ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']\n",
        "df = df[features + ['Approved_Flag']]"
      ],
      "metadata": {
        "id": "roXJ1UXMVLWB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# # Label Encoding all the Categorical Features\n",
        "['MARITALSTATUS', 'EDUCATION', 'GENDER' , 'last_prod_enq2' ,'first_prod_enq2']"
      ],
      "metadata": {
        "id": "Q0MCX3zBWpJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df['EDUCATION'] == 'SSC',['EDUCATION']]              = 1\n",
        "df.loc[df['EDUCATION'] == '12TH',['EDUCATION']]             = 2\n",
        "df.loc[df['EDUCATION'] == 'GRADUATE',['EDUCATION']]         = 3\n",
        "df.loc[df['EDUCATION'] == 'UNDER GRADUATE',['EDUCATION']]   = 3\n",
        "df.loc[df['EDUCATION'] == 'POST-GRADUATE',['EDUCATION']]    = 4\n",
        "df.loc[df['EDUCATION'] == 'OTHERS',['EDUCATION']]           = 1\n",
        "df.loc[df['EDUCATION'] == 'PROFESSIONAL',['EDUCATION']]     = 3"
      ],
      "metadata": {
        "id": "nJKMe94lWqO9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['EDUCATION'].value_counts()\n",
        "df['EDUCATION'] = df['EDUCATION'].astype(int)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "EWma5HYiWzvA",
        "outputId": "ce074329-5d32-4794-f510-11b0ec556b10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 42064 entries, 0 to 42063\n",
            "Data columns (total 43 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   pct_tl_open_L6M            42064 non-null  float64\n",
            " 1   pct_tl_closed_L6M          42064 non-null  float64\n",
            " 2   Tot_TL_closed_L12M         42064 non-null  int64  \n",
            " 3   pct_tl_closed_L12M         42064 non-null  float64\n",
            " 4   Tot_Missed_Pmnt            42064 non-null  int64  \n",
            " 5   CC_TL                      42064 non-null  int64  \n",
            " 6   Home_TL                    42064 non-null  int64  \n",
            " 7   PL_TL                      42064 non-null  int64  \n",
            " 8   Secured_TL                 42064 non-null  int64  \n",
            " 9   Unsecured_TL               42064 non-null  int64  \n",
            " 10  Other_TL                   42064 non-null  int64  \n",
            " 11  Age_Oldest_TL              42064 non-null  int64  \n",
            " 12  Age_Newest_TL              42064 non-null  int64  \n",
            " 13  time_since_recent_payment  42064 non-null  int64  \n",
            " 14  max_recent_level_of_deliq  42064 non-null  int64  \n",
            " 15  num_deliq_6_12mts          42064 non-null  int64  \n",
            " 16  num_times_60p_dpd          42064 non-null  int64  \n",
            " 17  num_std_12mts              42064 non-null  int64  \n",
            " 18  num_sub                    42064 non-null  int64  \n",
            " 19  num_sub_6mts               42064 non-null  int64  \n",
            " 20  num_sub_12mts              42064 non-null  int64  \n",
            " 21  num_dbt                    42064 non-null  int64  \n",
            " 22  num_dbt_12mts              42064 non-null  int64  \n",
            " 23  num_lss                    42064 non-null  int64  \n",
            " 24  recent_level_of_deliq      42064 non-null  int64  \n",
            " 25  CC_enq_L12m                42064 non-null  int64  \n",
            " 26  PL_enq_L12m                42064 non-null  int64  \n",
            " 27  time_since_recent_enq      42064 non-null  int64  \n",
            " 28  enq_L3m                    42064 non-null  int64  \n",
            " 29  NETMONTHLYINCOME           42064 non-null  int64  \n",
            " 30  Time_With_Curr_Empr        42064 non-null  int64  \n",
            " 31  CC_Flag                    42064 non-null  int64  \n",
            " 32  PL_Flag                    42064 non-null  int64  \n",
            " 33  pct_PL_enq_L6m_of_ever     42064 non-null  float64\n",
            " 34  pct_CC_enq_L6m_of_ever     42064 non-null  float64\n",
            " 35  HL_Flag                    42064 non-null  int64  \n",
            " 36  GL_Flag                    42064 non-null  int64  \n",
            " 37  MARITALSTATUS              42064 non-null  object \n",
            " 38  EDUCATION                  42064 non-null  int64  \n",
            " 39  GENDER                     42064 non-null  object \n",
            " 40  last_prod_enq2             42064 non-null  object \n",
            " 41  first_prod_enq2            42064 non-null  object \n",
            " 42  Approved_Flag              42064 non-null  object \n",
            "dtypes: float64(5), int64(33), object(5)\n",
            "memory usage: 13.8+ MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-c1e7fd256653>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['EDUCATION'] = df['EDUCATION'].astype(int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded = pd.get_dummies(df, columns=['MARITALSTATUS','GENDER', 'last_prod_enq2' ,'first_prod_enq2'])\n",
        "\n",
        "\n",
        "\n",
        "df_encoded.info()\n",
        "k = df_encoded.describe()"
      ],
      "metadata": {
        "id": "MySNJYUuW1xM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47961bac-cc8c-464b-ae07-b2ebb3342857"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 42064 entries, 0 to 42063\n",
            "Data columns (total 55 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   pct_tl_open_L6M               42064 non-null  float64\n",
            " 1   pct_tl_closed_L6M             42064 non-null  float64\n",
            " 2   Tot_TL_closed_L12M            42064 non-null  int64  \n",
            " 3   pct_tl_closed_L12M            42064 non-null  float64\n",
            " 4   Tot_Missed_Pmnt               42064 non-null  int64  \n",
            " 5   CC_TL                         42064 non-null  int64  \n",
            " 6   Home_TL                       42064 non-null  int64  \n",
            " 7   PL_TL                         42064 non-null  int64  \n",
            " 8   Secured_TL                    42064 non-null  int64  \n",
            " 9   Unsecured_TL                  42064 non-null  int64  \n",
            " 10  Other_TL                      42064 non-null  int64  \n",
            " 11  Age_Oldest_TL                 42064 non-null  int64  \n",
            " 12  Age_Newest_TL                 42064 non-null  int64  \n",
            " 13  time_since_recent_payment     42064 non-null  int64  \n",
            " 14  max_recent_level_of_deliq     42064 non-null  int64  \n",
            " 15  num_deliq_6_12mts             42064 non-null  int64  \n",
            " 16  num_times_60p_dpd             42064 non-null  int64  \n",
            " 17  num_std_12mts                 42064 non-null  int64  \n",
            " 18  num_sub                       42064 non-null  int64  \n",
            " 19  num_sub_6mts                  42064 non-null  int64  \n",
            " 20  num_sub_12mts                 42064 non-null  int64  \n",
            " 21  num_dbt                       42064 non-null  int64  \n",
            " 22  num_dbt_12mts                 42064 non-null  int64  \n",
            " 23  num_lss                       42064 non-null  int64  \n",
            " 24  recent_level_of_deliq         42064 non-null  int64  \n",
            " 25  CC_enq_L12m                   42064 non-null  int64  \n",
            " 26  PL_enq_L12m                   42064 non-null  int64  \n",
            " 27  time_since_recent_enq         42064 non-null  int64  \n",
            " 28  enq_L3m                       42064 non-null  int64  \n",
            " 29  NETMONTHLYINCOME              42064 non-null  int64  \n",
            " 30  Time_With_Curr_Empr           42064 non-null  int64  \n",
            " 31  CC_Flag                       42064 non-null  int64  \n",
            " 32  PL_Flag                       42064 non-null  int64  \n",
            " 33  pct_PL_enq_L6m_of_ever        42064 non-null  float64\n",
            " 34  pct_CC_enq_L6m_of_ever        42064 non-null  float64\n",
            " 35  HL_Flag                       42064 non-null  int64  \n",
            " 36  GL_Flag                       42064 non-null  int64  \n",
            " 37  EDUCATION                     42064 non-null  int64  \n",
            " 38  Approved_Flag                 42064 non-null  object \n",
            " 39  MARITALSTATUS_Married         42064 non-null  bool   \n",
            " 40  MARITALSTATUS_Single          42064 non-null  bool   \n",
            " 41  GENDER_F                      42064 non-null  bool   \n",
            " 42  GENDER_M                      42064 non-null  bool   \n",
            " 43  last_prod_enq2_AL             42064 non-null  bool   \n",
            " 44  last_prod_enq2_CC             42064 non-null  bool   \n",
            " 45  last_prod_enq2_ConsumerLoan   42064 non-null  bool   \n",
            " 46  last_prod_enq2_HL             42064 non-null  bool   \n",
            " 47  last_prod_enq2_PL             42064 non-null  bool   \n",
            " 48  last_prod_enq2_others         42064 non-null  bool   \n",
            " 49  first_prod_enq2_AL            42064 non-null  bool   \n",
            " 50  first_prod_enq2_CC            42064 non-null  bool   \n",
            " 51  first_prod_enq2_ConsumerLoan  42064 non-null  bool   \n",
            " 52  first_prod_enq2_HL            42064 non-null  bool   \n",
            " 53  first_prod_enq2_PL            42064 non-null  bool   \n",
            " 54  first_prod_enq2_others        42064 non-null  bool   \n",
            "dtypes: bool(16), float64(5), int64(33), object(1)\n",
            "memory usage: 13.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Modelling and Model Tuning"
      ],
      "metadata": {
        "id": "YqGAEtv4QcyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Random Forest"
      ],
      "metadata": {
        "id": "UReTWlQTRlWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = df_encoded['Approved_Flag']\n",
        "x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf_classifier = RandomForestClassifier(n_estimators = 200, random_state=42)\n",
        "\n",
        "rf_classifier.fit(x_train, y_train)\n",
        "\n",
        "y_pred = rf_classifier.predict(x_test)"
      ],
      "metadata": {
        "id": "IqA1mHR1QS6N"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08E-CTtKQ3Qe",
        "outputId": "b3f8e429-09f6-47e9-ca91-080ed5a2ba00"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7636990372043266"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
        "\n",
        "\n",
        "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
        "    print(f\"Class {v}:\")\n",
        "    print(f\"Precision: {precision[i]}\")\n",
        "    print(f\"Recall: {recall[i]}\")\n",
        "    print(f\"F1 Score: {f1_score[i]}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-QD0VoQRUlB",
        "outputId": "b815ba0c-91fa-4c5b-a1f9-02962c85e919"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class p1:\n",
            "Precision: 0.8370457209847597\n",
            "Recall: 0.7041420118343196\n",
            "F1 Score: 0.7648634172469203\n",
            "\n",
            "Class p2:\n",
            "Precision: 0.7957519116397621\n",
            "Recall: 0.9282457879088206\n",
            "F1 Score: 0.8569075937785909\n",
            "\n",
            "Class p3:\n",
            "Precision: 0.4423380726698262\n",
            "Recall: 0.21132075471698114\n",
            "F1 Score: 0.28600612870275793\n",
            "\n",
            "Class p4:\n",
            "Precision: 0.7178502879078695\n",
            "Recall: 0.7269193391642371\n",
            "F1 Score: 0.7223563495895703\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2: XGBoost"
      ],
      "metadata": {
        "id": "vB7niE9PRpXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "xgb_classifier = xgb.XGBClassifier(objective='multi:softmax',  num_class=4)\n",
        "\n",
        "\n",
        "\n",
        "y = df_encoded['Approved_Flag']\n",
        "x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "xgb_classifier.fit(x_train, y_train)\n",
        "y_pred = xgb_classifier.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print ()\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print ()\n",
        "\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
        "\n",
        "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
        "    print(f\"Class {v}:\")\n",
        "    print(f\"Precision: {precision[i]}\")\n",
        "    print(f\"Recall: {recall[i]}\")\n",
        "    print(f\"F1 Score: {f1_score[i]}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zFhK9wzRfT0",
        "outputId": "8de75725-d041-4b99-882f-584b098ddda0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 0.78\n",
            "\n",
            "Class p1:\n",
            "Precision: 0.823906083244397\n",
            "Recall: 0.7613412228796844\n",
            "F1 Score: 0.7913890312660173\n",
            "\n",
            "Class p2:\n",
            "Precision: 0.8255418233924413\n",
            "Recall: 0.913577799801784\n",
            "F1 Score: 0.8673315769665036\n",
            "\n",
            "Class p3:\n",
            "Precision: 0.4756380510440835\n",
            "Recall: 0.30943396226415093\n",
            "F1 Score: 0.3749428440786465\n",
            "\n",
            "Class p4:\n",
            "Precision: 0.7342386032977691\n",
            "Recall: 0.7356656948493683\n",
            "F1 Score: 0.7349514563106796\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning in XGBoost\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the XGBClassifier with the initial set of hyperparameters\n",
        "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=4)\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Evaluate the model with the best hyperparameters on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "accuracy = best_model.score(x_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "# Best Hyperparameters: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}\n",
        "\n",
        "\n",
        "# Based on risk appetite of the bank, you will suggest P1,P2,P3,P4 to the business end user\n",
        "\n",
        "# # Hyperparameter tuning for XGBoost\n",
        "\n",
        "# # Define the hyperparameter grid\n",
        "# param_grid = {\n",
        "#   'colsample_bytree': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
        "#   'learning_rate'   : [0.001, 0.01, 0.1, 1],\n",
        "#   'max_depth'       : [3, 5, 8, 10],\n",
        "#   'alpha'           : [1, 10, 100],\n",
        "#   'n_estimators'    : [10,50,100]\n",
        "# }\n",
        "\n",
        "# index = 0\n",
        "\n",
        "# answers_grid = {\n",
        "#     'combination'       :[],\n",
        "#     'train_Accuracy'    :[],\n",
        "#     'test_Accuracy'     :[],\n",
        "#     'colsample_bytree'  :[],\n",
        "#     'learning_rate'     :[],\n",
        "#     'max_depth'         :[],\n",
        "#     'alpha'             :[],\n",
        "#     'n_estimators'      :[]\n",
        "\n",
        "#     }\n",
        "\n",
        "\n",
        "# # Loop through each combination of hyperparameters\n",
        "# for colsample_bytree in param_grid['colsample_bytree']:\n",
        "#   for learning_rate in param_grid['learning_rate']:\n",
        "#     for max_depth in param_grid['max_depth']:\n",
        "#       for alpha in param_grid['alpha']:\n",
        "#           for n_estimators in param_grid['n_estimators']:\n",
        "\n",
        "#               index = index + 1\n",
        "\n",
        "#               # Define and train the XGBoost model\n",
        "#               model = xgb.XGBClassifier(objective='multi:softmax',\n",
        "#                                        num_class=4,\n",
        "#                                        colsample_bytree = colsample_bytree,\n",
        "#                                        learning_rate = learning_rate,\n",
        "#                                        max_depth = max_depth,\n",
        "#                                        alpha = alpha,\n",
        "#                                        n_estimators = n_estimators)\n",
        "\n",
        "\n",
        "\n",
        "#               y = df_encoded['Approved_Flag']\n",
        "#               x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
        "\n",
        "#               label_encoder = LabelEncoder()\n",
        "#               y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "\n",
        "#               x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "#               model.fit(x_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "#               # Predict on training and testing sets\n",
        "#               y_pred_train = model.predict(x_train)\n",
        "#               y_pred_test = model.predict(x_test)\n",
        "\n",
        "\n",
        "#               # Calculate train and test results\n",
        "\n",
        "#               train_accuracy =  accuracy_score (y_train, y_pred_train)\n",
        "#               test_accuracy  =  accuracy_score (y_test , y_pred_test)\n",
        "\n",
        "\n",
        "\n",
        "#               # Include into the lists\n",
        "#               answers_grid ['combination']   .append(index)\n",
        "#               answers_grid ['train_Accuracy']    .append(train_accuracy)\n",
        "#               answers_grid ['test_Accuracy']     .append(test_accuracy)\n",
        "#               answers_grid ['colsample_bytree']   .append(colsample_bytree)\n",
        "#               answers_grid ['learning_rate']      .append(learning_rate)\n",
        "#               answers_grid ['max_depth']          .append(max_depth)\n",
        "#               answers_grid ['alpha']              .append(alpha)\n",
        "#               answers_grid ['n_estimators']       .append(n_estimators)\n",
        "\n",
        "\n",
        "#               # Print results for this combination\n",
        "#               print(f\"Combination {index}\")\n",
        "#               print(f\"colsample_bytree: {colsample_bytree}, learning_rate: {learning_rate}, max_depth: {max_depth}, alpha: {alpha}, n_estimators: {n_estimators}\")\n",
        "#               print(f\"Train Accuracy: {train_accuracy:.2f}\")\n",
        "#               print(f\"Test Accuracy : {test_accuracy :.2f}\")\n",
        "#               print(\"-\" * 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_ucd8-kRomV",
        "outputId": "43837a24-54d4-4637-e04a-0deb85170c69"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}\n",
            "Test Accuracy: 0.7811719957209081\n"
          ]
        }
      ]
    }
  ]
}